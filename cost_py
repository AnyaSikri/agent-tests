import requests
from bs4 import BeautifulSoup
import csv
import re
import urllib.request
from typing import List, Dict, Optional

# Cost categories
COST_CATEGORIES = {
    "Low Cost": {"max_rate": 0.001, "description": "Input rate â‰¤ $0.001 per 1K tokens"},
    "Medium Cost": {"min_rate": 0.001, "max_rate": 0.005, "description": "Input rate $0.001 - $0.005 per 1K tokens"},
    "High Cost": {"min_rate": 0.005, "description": "Input rate > $0.005 per 1K tokens"}
}

def fetch_html(url: str) -> str:
    """Fetch HTML content from URL using urllib (from latency.py approach)"""
    with urllib.request.urlopen(url) as response:
        html = response.read().decode("utf-8")
    return html

def parse_master_model_ids(html: str) -> List[Dict]:
    """Parse model information from AWS Bedrock documentation (from latency.py)"""
    soup = BeautifulSoup(html, "html.parser")
    models = []
    tables = soup.find_all("table")
    for table in tables:
        headers = [th.get_text(strip=True) for th in table.find_all("th")]
        for row in table.find_all("tr")[1:]:
            cells = row.find_all("td")
            if len(cells) != len(headers):
                continue
            model_info = {headers[i]: cells[i].get_text(strip=True) for i in range(len(headers))}
            # Add Model ID for matching
            if "Model ID" in model_info:
                model_info["model-id"] = model_info["Model ID"]
            elif "Model Id" in model_info:
                model_info["model-id"] = model_info["Model Id"]
            elif "Model" in model_info:
                model_info["model-id"] = model_info["Model"]
            else:
                model_info["model-id"] = cells[0].get_text(strip=True)
            models.append(model_info)
    return models

def get_model_names_from_documentation() -> List[str]:
    """Fetch model names from AWS Bedrock documentation"""
    master_url = "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html"
    try:
        print("Fetching model catalog from AWS Bedrock documentation...")
        master_html = fetch_html(master_url)
        master_models = parse_master_model_ids(master_html)
        
        # Extract model names/IDs for analysis
        model_names = []
        for model in master_models:
            model_id = model.get("model-id", "")
            if model_id:
                model_names.append(model_id)
        
        print(f"Found {len(model_names)} models in documentation")
        return model_names
    except Exception as e:
        print(f"Error fetching model names from documentation: {e}")
        print("Falling back to sample model names...")
        # Fallback to sample models if scraping fails
        return [
            "Claude 3.7 Sonnet",
            "Llama 3.1 405B Instruct", 
            "Mistral 7B Instruct",
            "Nova Lite",
            "DeepSeek-R1"
        ]

def fetch_bedrock_pricing_page() -> str:
    """Fetch the AWS Bedrock pricing page using urllib approach"""
    url = "https://aws.amazon.com/bedrock/pricing/"
    try:
        return fetch_html(url)
    except Exception as e:
        print(f"Error fetching pricing page: {e}")
        return ""

def extract_pricing_data(html: str) -> Dict[str, Dict[str, float]]:
    """Extract pricing data from the HTML content"""
    soup = BeautifulSoup(html, "html.parser")
    pricing_data = {}
    
    # Look for pricing tables
    tables = soup.find_all("table")
    
    for table in tables:
        rows = table.find_all("tr")
        if not rows:
            continue
            
        # Look for headers that might indicate pricing information
        headers = [th.get_text(strip=True).lower() for th in rows[0].find_all(["th", "td"])]
        
        # Check if this table contains pricing information
        if any(keyword in " ".join(headers) for keyword in ["model", "input", "output", "per", "token", "1k", "1000"]):
            for row in rows[1:]:
                cells = row.find_all(["td", "th"])
                if len(cells) >= 2:
                    model_name = cells[0].get_text(strip=True)
                    price_text = cells[1].get_text(strip=True)
                    
                    # Extract price per 1K tokens
                    price_match = re.search(r'\$?([\d,]+\.?\d*)', price_text)
                    if price_match:
                        try:
                            price = float(price_match.group(1).replace(',', ''))
                            # Convert to per 1K tokens if needed
                            if "per token" in price_text.lower():
                                price *= 1000
                            elif "per 1000 tokens" in price_text.lower() or "per 1k tokens" in price_text.lower():
                                pass  # Already per 1K tokens
                            
                            pricing_data[model_name] = {
                                "input_rate_per_1k": price,
                                "raw_text": price_text
                            }
                        except ValueError:
                            continue
    
    return pricing_data

def match_model_names(input_models: List[str], pricing_data: Dict[str, Dict[str, float]]) -> Dict[str, Optional[Dict[str, float]]]:
    """Match input model names to pricing data"""
    matched_data = {}
    
    for model_name in input_models:
        # Try exact match first
        if model_name in pricing_data:
            matched_data[model_name] = pricing_data[model_name]
            continue
            
        # Try partial matching
        best_match = None
        best_score = 0
        
        for pricing_model, pricing_info in pricing_data.items():
            # Simple similarity scoring
            model_words = set(model_name.lower().split())
            pricing_words = set(pricing_model.lower().split())
            
            if model_words & pricing_words:  # If there's any overlap
                score = len(model_words & pricing_words) / len(model_words | pricing_words)
                if score > best_score:
                    best_score = score
                    best_match = pricing_info
        
        if best_match and best_score > 0.3:  # Threshold for matching
            matched_data[model_name] = best_match
        else:
            matched_data[model_name] = None
    
    return matched_data

def categorize_cost(input_rate_per_1k: float) -> str:
    """Categorize cost based on input rate per 1K tokens"""
    if input_rate_per_1k <= COST_CATEGORIES["Low Cost"]["max_rate"]:
        return "Low Cost"
    elif input_rate_per_1k <= COST_CATEGORIES["Medium Cost"]["max_rate"]:
        return "Medium Cost"
    else:
        return "High Cost"

def analyze_model_costs(matched_data: Dict[str, Optional[Dict[str, float]]]) -> List[Dict[str, str]]:
    """Analyze and categorize model costs"""
    results = []
    
    for model_name, pricing_info in matched_data.items():
        if pricing_info:
            input_rate = pricing_info["input_rate_per_1k"]
            cost_category = categorize_cost(input_rate)
            results.append({
                "Model Name": model_name,
                "Input Rate per 1K tokens": f"${input_rate:.6f}",
                "Cost Category": cost_category,
                "Category Description": COST_CATEGORIES[cost_category]["description"],
                "Raw Pricing Text": pricing_info["raw_text"]
            })
        else:
            results.append({
                "Model Name": model_name,
                "Input Rate per 1K tokens": "Not found",
                "Cost Category": "Unknown",
                "Category Description": "Pricing information not available",
                "Raw Pricing Text": "N/A"
            })
    
    return results

def write_results_to_csv(results: List[Dict[str, str]], filename: str = "cost_analysis_output.csv") -> None:
    """Write results to CSV file"""
    if not results:
        print("No results to write.")
        return
        
    with open(filename, "w", newline="", encoding="utf-8") as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=results[0].keys())
        writer.writeheader()
        writer.writerows(results)
    print(f"Results written to {filename}")

def main():
    print("AWS Bedrock Model Cost Analysis")
    print("=" * 50)
    
    print("\nModels to analyze:")
    model_names = get_model_names_from_documentation()
    for name in model_names:
        print(f"- {name}")
    
    print("\nCost Categories:")
    for category, info in COST_CATEGORIES.items():
        print(f"- {category}: {info['description']}")
    
    print("\nFetching AWS Bedrock pricing page...")
    html = fetch_bedrock_pricing_page()
    
    if not html:
        print("Failed to fetch pricing page. Using sample data for demonstration.")
        # Sample pricing data for demonstration
        sample_pricing = {
            "Claude 3.7 Sonnet": {"input_rate_per_1k": 0.003, "raw_text": "$0.003 per 1K input tokens"},
            "Llama 3.1 405B Instruct": {"input_rate_per_1k": 0.0008, "raw_text": "$0.0008 per 1K input tokens"},
            "Mistral 7B Instruct": {"input_rate_per_1k": 0.00015, "raw_text": "$0.00015 per 1K input tokens"},
            "Nova Lite": {"input_rate_per_1k": 0.0001, "raw_text": "$0.0001 per 1K input tokens"},
            "DeepSeek-R1": {"input_rate_per_1k": 0.006, "raw_text": "$0.006 per 1K input tokens"}
        }
        pricing_data = sample_pricing
    else:
        print("Parsing pricing data...")
        pricing_data = extract_pricing_data(html)
        print(f"Found pricing data for {len(pricing_data)} models")
    
    print("\nMatching model names to pricing data...")
    matched_data = match_model_names(model_names, pricing_data)
    
    print("\nAnalyzing costs...")
    results = analyze_model_costs(matched_data)
    
    print("\nCost Analysis Results:")
    print("-" * 80)
    for result in results:
        print(f"Model: {result['Model Name']}")
        print(f"  Input Rate: {result['Input Rate per 1K tokens']}")
        print(f"  Cost Category: {result['Cost Category']}")
        print(f"  Description: {result['Category Description']}")
        print()
    
    write_results_to_csv(results)
    
    # Summary statistics
    categories = [r["Cost Category"] for r in results if r["Cost Category"] != "Unknown"]
    if categories:
        print("\nSummary:")
        for category in COST_CATEGORIES.keys():
            count = categories.count(category)
            if count > 0:
                print(f"- {category}: {count} model(s)")

if __name__ == "__main__":
    main()
